{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import dlib\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'contempt',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'happiness',\n",
       " 'neutral',\n",
       " 'sadness',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = [\"anger\", \"contempt\", \"disgust\", \"fear\",\n",
    "            \"happiness\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) #Для повышения контраста изображения применяется адаптивная эквализация \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Установим классификатор метод опорных векторов с полиномиальным ядром\n",
    "clf = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сделать словарь для всех значений\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определить функцию для получения списка файлов,\n",
    "# случайным образом перетасовать его и разделить на 80/20\n",
    "def get_files(emotion):\n",
    "    \n",
    "    files = glob.glob(\"database\\sorted_set\\%s\\*\" % emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)]\n",
    "    prediction = files[-int(len(files)*0.2):]\n",
    "    \n",
    "    return training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): # Для всех обнаруженных экземпляров лица в отдельности\n",
    "        shape = predictor(image, d) # Нарисовать лич.точки с классом прогнозирования\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        \n",
    "        # Сохранить координаты X и Y в двух списках\n",
    "        for i in range(0, 68):\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "            \n",
    "        # Ищем сред.точки\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        \n",
    "        # Ищем сред. точку на лице\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "            landmarks_vectorised.append(w)\n",
    "            landmarks_vectorised.append(z)\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append((math.atan2(y, x)*360)/(2*math.pi))\n",
    "\n",
    "        data['landmarks_vectorised'] = landmarks_vectorised\n",
    "    if len(detections) < 1: \n",
    "        data['landmarks_vestorised'] = \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sets():\n",
    "    \n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        print(\" Работаем с  %s\" %emotion)\n",
    "        training, prediction = get_files(emotion)\n",
    "        \n",
    "        # Добавим данные в список обучения и прогнозирования и сгенерируем метки 0-7\n",
    "        for item in training:\n",
    "            image = cv2.imread(item) # открываем изображение\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # конверт в серый цвет\n",
    "            clahe_image = clahe.apply(gray)\n",
    "            get_landmarks(clahe_image)\n",
    "            if data['landmarks_vectorised'] == \"error\":\n",
    "                print(\"no face detected on this one\")\n",
    "            else:\n",
    "                training_data.append(data['landmarks_vectorised']) # добавим массив изображений в обучающую выборку\n",
    "                training_labels.append(emotions.index(emotion))\n",
    "    \n",
    "        for item in prediction:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            clahe_image = clahe.apply(gray)\n",
    "            get_landmarks(clahe_image)\n",
    "            if data['landmarks_vectorised'] == \"Ошибка\":\n",
    "                print(\"Не найдено лицо\")\n",
    "            else:\n",
    "                prediction_data.append(data['landmarks_vectorised'])\n",
    "                prediction_labels.append(emotions.index(emotion))\n",
    "    \n",
    "    return np.array(training_data), np.array(training_labels), \\\n",
    "           np.array(prediction_data), np.array(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Круг 0\n",
      " Работаем с  anger\n",
      " Работаем с  contempt\n",
      " Работаем с  disgust\n",
      " Работаем с  fear\n",
      " Работаем с  happiness\n",
      " Работаем с  neutral\n",
      " Работаем с  sadness\n",
      " Работаем с  surprise\n",
      "Обучение SVM linear 0\n",
      "Для круга  0\n",
      "Lenear:  0.881818181818\n",
      "Среднее значениеe lin svm: 0.881818181818\n"
     ]
    }
   ],
   "source": [
    "accur_lin = []\n",
    "for i in range(0, 1): # сколько обучаться кругов будет\n",
    "    \n",
    "    # Получим из массива данные\n",
    "    print(\"Круг %s\" % i)\n",
    "    X_train, y_train, X_test, y_test = make_sets()\n",
    "\n",
    "    print(\"Обучение SVM linear %s\" % i)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Делаем обучающую выборку для классификатора\n",
    "    print(\"Для круга  %s\" % i) \n",
    "    pred_lin = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Lenear: \", pred_lin)\n",
    "    \n",
    "    # Наша точность\n",
    "    accur_lin.append(pred_lin)\n",
    "\n",
    "# Получим среднюю точность работы\n",
    "print(\"Среднее значениеe lin svm: %s\" % np.mean(accur_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save classifier\n",
    "with open('svr.pickle', 'wb') as f:\n",
    "  pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = pickle.load(open('svr.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-ae2f9e79a675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnmbr_of_test_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm_percent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnmbr_of_test_examples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcm_percent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "nmbr_of_test_examples = len(y_test)\n",
    "cm_percent = cm / nmbr_of_test_examples\n",
    "cm_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-9802bb20059a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Предсказанный класс'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Настоящий класс'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update(\n",
    "    {\n",
    "        'font.size': 16,\n",
    "#         'font.family': 'Times New Roman'\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Настоящий класс')\n",
    "for (i, j), z in np.ndenumerate(cm_percent):\n",
    "    if i==4 and j==4:\n",
    "        plt.text(j, i, '{:0.1f} %'.format(z), ha='center', va='center',\n",
    "                 color='w')\n",
    "    else:\n",
    "        plt.text(j, i, '{:0.1f} %'.format(z), ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save classifier\n",
    "# with open('svr.pickle', 'wb') as f:\n",
    "#     pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# how to load a model\n",
    "# clf = pickle.load(open('svr.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(emotion):\n",
    "    \n",
    "    files = glob.glob(\"database\\sorted_set\\%s\\*\" % emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)]\n",
    "    prediction = files[-int(len(files)*0.2):]\n",
    "    \n",
    "    return training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['database\\\\sorted_set\\\\anger\\\\11_004_00000021.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\03_001_00000071.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\11_006_00000010.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\29_006_00000010.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\42_004_00000020.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\45_005_00000030.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\26_008_00000029.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\27_010_00000018.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\99_001_00000018.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\36_005_00000010.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\00_005_00000023.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\02_001_00000016.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\92_003_00000014.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\28_001_00000024.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\17_006_00000010.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\10_004_00000019.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\30_007_00000020.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\90_007_00000014.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\32_003_00000017.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\09_003_00000017.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\89_003_00000036.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\26_003_00000015.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\34_003_00000011.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\71_004_00000028.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\66_005_00000011.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\87_007_00000016.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\06_001_00000040.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\55_004_00000028.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\67_004_00000023.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\37_003_00000022.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\50_004_00000021.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\14_003_00000030.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\04_001_00000022.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\82_005_00000017.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\12_005_00000017.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\29_001_00000019.png'],\n",
       " ['database\\\\sorted_set\\\\anger\\\\75_008_00000012.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\72_005_00000019.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\13_008_00000023.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\34_003_00000027.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\58_005_00000010.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\19_008_00000018.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\22_005_00000032.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\33_003_00000047.png',\n",
       "  'database\\\\sorted_set\\\\anger\\\\01_001_00000067.png'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files(emotions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_cnn = ([[6,0,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
